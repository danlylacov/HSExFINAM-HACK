import pandas as pd
import numpy as np
from datetime import datetime, timedelta

def create_sample_data(filename="sample_stock_data.csv", n_days=100):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    
    Args:
        filename: –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        n_days: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö
    """
    np.random.seed(42)
    
    # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    base_price = 100.0
    base_volume = 1000000
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç
    start_date = datetime(2024, 1, 1)
    dates = [start_date + timedelta(days=i) for i in range(n_days)]
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    data = []
    
    for i, date in enumerate(dates):
        # –¶–µ–Ω—ã —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é
        trend = 0.001 * i  # –Ω–µ–±–æ–ª—å—à–æ–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
        volatility = 0.02 + 0.01 * np.sin(i * 0.1)  # –∏–∑–º–µ–Ω—è—é—â–∞—è—Å—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        
        # OHLC —Ü–µ–Ω—ã
        open_price = base_price * (1 + trend + np.random.normal(0, volatility))
        close_price = open_price * (1 + np.random.normal(0, volatility * 0.5))
        high_price = max(open_price, close_price) * (1 + abs(np.random.normal(0, volatility * 0.3)))
        low_price = min(open_price, close_price) * (1 - abs(np.random.normal(0, volatility * 0.3)))
        
        # –û–±—ä–µ–º —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π –∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        volume_multiplier = 1 + volatility * 2
        volume = int(base_volume * volume_multiplier * (1 + np.random.normal(0, 0.2)))
        
        # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        news_count = np.random.randint(20, 80)
        news_sum = np.random.uniform(0.5, 2.5)
        news_mean = news_sum / news_count
        news_max = np.random.uniform(0.1, 0.4)
        
        # –°–µ–Ω—Ç–∏–º–µ–Ω—Ç –¥–∞–Ω–Ω—ã–µ
        sentiment_count = np.random.randint(30, 70)
        sentiment_mean = np.random.uniform(0.3, 0.7)
        sentiment_sum = sentiment_mean * sentiment_count
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞
        pos_count = int(sentiment_count * np.random.uniform(0.3, 0.6))
        neg_count = int(sentiment_count * np.random.uniform(0.1, 0.3))
        neutral_count = sentiment_count - pos_count - neg_count
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        rsi = np.random.uniform(20, 80)
        macd = np.random.uniform(-2, 2)
        cci = np.random.uniform(-100, 100)
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        ema9 = base_price * (1 + trend + np.random.normal(0, volatility * 0.5))
        ema50 = base_price * (1 + trend + np.random.normal(0, volatility * 0.3))
        
        # –°–≤–µ—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—Ä–µ–¥–∫–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è)
        patterns = {
            'areThreeWhiteSoldiers': 1 if np.random.random() < 0.05 else 0,
            'areThreeBlackCrows': 1 if np.random.random() < 0.05 else 0,
            'doji': 1 if np.random.random() < 0.1 else 0,
            'bearishEngulfing': 1 if np.random.random() < 0.05 else 0,
            'bullishEngulfing': 1 if np.random.random() < 0.05 else 0
        }
        
        row = {
            'ticker': 'SAMPLE',
            'begin': date.strftime('%Y-%m-%d'),
            'nn_news_sum': round(news_sum, 3),
            'nn_news_mean': round(news_mean, 4),
            'nn_news_max': round(news_max, 3),
            'nn_news_count': news_count,
            'sentiment_mean': round(sentiment_mean, 3),
            'sentiment_sum': round(sentiment_sum, 1),
            'sentiment_count': sentiment_count,
            'sentiment_positive_count': pos_count,
            'sentiment_negative_count': neg_count,
            'sentiment_neutral_count': neutral_count,
            'rsi': round(rsi, 1),
            'macd': round(macd, 3),
            'cci': round(cci, 1),
            'ema9': round(ema9, 2),
            'ema50': round(ema50, 2),
            'areThreeWhiteSoldiers': patterns['areThreeWhiteSoldiers'],
            'areThreeBlackCrows': patterns['areThreeBlackCrows'],
            'doji': patterns['doji'],
            'bearishEngulfing': patterns['bearishEngulfing'],
            'bullishEngulfing': patterns['bullishEngulfing'],
            'open': round(open_price, 2),
            'high': round(high_price, 2),
            'low': round(low_price, 2),
            'close': round(close_price, 2),
            'volume': volume
        }
        
        data.append(row)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    df = pd.DataFrame(data)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
    df.to_csv(filename, index=False)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª {filename}")
    print(f"   –°—Ç—Ä–æ–∫: {len(df)}")
    print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
    print(f"   –ü–µ—Ä–∏–æ–¥: {df['begin'].min()} - {df['begin'].max()}")
    print(f"   –¶–µ–Ω—ã: {df['open'].min():.2f} - {df['open'].max():.2f}")
    print(f"   –û–±—ä–µ–º—ã: {df['volume'].min():,} - {df['volume'].max():,}")
    
    return df

def create_multiple_tickers(filename="multi_ticker_data.csv", tickers=['AFLT', 'SBER', 'GAZP'], days_per_ticker=50):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∏–∫–µ—Ä–æ–≤
    """
    all_data = []
    
    for ticker in tickers:
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker}...")
        ticker_data = create_sample_data(f"temp_{ticker}.csv", days_per_ticker)
        ticker_data['ticker'] = ticker
        all_data.append(ticker_data)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    combined_df = pd.concat(all_data, ignore_index=True)
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ
    combined_df = combined_df.sort_values(['ticker', 'begin']).reset_index(drop=True)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    combined_df.to_csv(filename, index=False)
    
    print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª {filename}")
    print(f"   –¢–∏–∫–µ—Ä–æ–≤: {len(tickers)}")
    print(f"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(combined_df)}")
    print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(combined_df.columns)}")
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    for ticker in tickers:
        import os
        os.remove(f"temp_{ticker}.csv")
    
    return combined_df

if __name__ == "__main__":
    print("=== –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ===")
    print()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
    print("1. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ (100 –¥–Ω–µ–π):")
    create_sample_data("sample_data.csv", 100)
    
    print("\n" + "="*50 + "\n")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
    print("2. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ (200 –¥–Ω–µ–π):")
    create_sample_data("extended_sample_data.csv", 200)
    
    print("\n" + "="*50 + "\n")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º—É–ª—å—Ç–∏-—Ç–∏–∫–µ—Ä –ø—Ä–∏–º–µ—Ä–∞
    print("3. –°–æ–∑–¥–∞–Ω–∏–µ –º—É–ª—å—Ç–∏-—Ç–∏–∫–µ—Ä –ø—Ä–∏–º–µ—Ä–∞:")
    create_multiple_tickers("multi_ticker_data.csv", ['AFLT', 'SBER', 'GAZP'], 60)
    
    print("\nüéâ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω—ã!")
    print("\nüìã –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print("   - sample_data.csv (100 –¥–Ω–µ–π, 1 —Ç–∏–∫–µ—Ä)")
    print("   - extended_sample_data.csv (200 –¥–Ω–µ–π, 1 —Ç–∏–∫–µ—Ä)")
    print("   - multi_ticker_data.csv (60 –¥–Ω–µ–π, 3 —Ç–∏–∫–µ—Ä–∞)")
    print("\nüöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
    print("   python3 quick_train.sh sample_data.csv")
